{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "464d6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tiktoken --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee826988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tiktoken # for token counting\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d41cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESEMPIO DI FORMATTAZIONE DEI TESTI PER IL FINE-TUNING DI GPT\n",
    "# {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "# {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
    "# {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da74827",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a text classifier.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f5fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(\"../data/input/sdg_17_labels_classification_dataset_4760_texts_TRAIN_2023.12.11.xlsx\")[['text', 'sdg']].rename(columns={'sdg': 'label'})\n",
    "val_df = pd.read_excel(\"../data/input/sdg_17_labels_classification_dataset_1020_texts_DEV_2023.12.11.xlsx\")[['text', 'sdg']].rename(columns={'sdg': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432cb193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This Vitamin Reduces Mental Health Problems By...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'League Of Legends' unveils new Arena game mod...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Community remembers Maddi Kingsbury at public ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  This Vitamin Reduces Mental Health Problems By...      0\n",
       "1  'League Of Legends' unveils new Arena game mod...      0\n",
       "2  Community remembers Maddi Kingsbury at public ...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fceda998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Murray revealed on Sky Sports, “I hope not, bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With age and inactive lifestyle, your joints a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Reuters) -Home health and hospice caregiver A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Murray revealed on Sky Sports, “I hope not, bu...      0\n",
       "1  With age and inactive lifestyle, your joints a...      0\n",
       "2  (Reuters) -Home health and hospice caregiver A...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e232f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_content_part1 = \"\"\"Classify the following input text within triple quotes according to the following Sustainable Development Goals (SDGs) dictionary of labels:\n",
    "\n",
    "\"SDG-1\": \"End poverty in all its forms everywhere.\"\n",
    "\"SDG-2\": \"End hunger, achieve food security and improved nutrition and promote sustainable agriculture.\"\n",
    "\"SDG-3\": \"Ensure healthy lives and promote well-being for all at all ages.\"\n",
    "\"SDG-4\": \"Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all.\"\n",
    "\"SDG-5\": \"Achieve gender equality and empower all women and girls.\"\n",
    "\"SDG-6\": \"Ensure availability and sustainable management of water and sanitation for all.\"\n",
    "\"SDG-7\": \"Ensure access to affordable, reliable, sustainable and modern energy for all.\"\n",
    "\"SDG-8\": \"Promote sustained, inclusive and sustainable economic growth, full and productive employment and decent work for all.\"\n",
    "\"SDG-9\": \"Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation.\"\n",
    "\"SDG-10\": \"Reduce inequality within and among countries.\"\n",
    "\"SDG-11\": \"Make cities and human settlements inclusive, safe, resilient and sustainable.\"\n",
    "\"SDG-12\": \"Ensure sustainable consumption and production patterns.\"\n",
    "\"SDG-13\": \"Take urgent action to combat climate change and its impacts.\"\n",
    "\"SDG-14\": \"Conserve and sustainably use the oceans, seas and marine resources for sustainable development.\"\n",
    "\"SDG-15\": \"Protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, halt and reverse land degradation, and halt biodiversity loss.\"\n",
    "\"SDG-16\": \"Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels.\"\n",
    "\"SDG-0\": \"Other.\"\n",
    "\n",
    "Choose ONLY ONE label for each input text.\n",
    "\n",
    "DO NOT include the input text in your answer.\n",
    "\n",
    "The input text is:\n",
    "'''\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c4e8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "for ind, row in train_df.iterrows():\n",
    "    train_dataset.append(\n",
    "        {\"messages\": [{\"role\": \"system\", \"content\": system_content}, \n",
    "                      {\"role\": \"user\", \"content\": user_content_part1 + row['text'] + \"\\n'''\"}, \n",
    "                      {\"role\": \"assistant\", \"content\": '\"SDG-'+str(row['label'])+'\"'}\n",
    "                     ]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca4c9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = []\n",
    "for ind, row in val_df.iterrows():\n",
    "    val_dataset.append(\n",
    "        {\"messages\": [{\"role\": \"system\", \"content\": system_content}, \n",
    "                      {\"role\": \"user\", \"content\": user_content_part1 + row['text'] + \"\\n'''\"}, \n",
    "                      {\"role\": \"assistant\", \"content\": '\"SDG-'+str(row['label'])+'\"'}\n",
    "                     ]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a4ed36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system', 'content': 'You are a text classifier.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Classify the following input text within triple quotes according to the following Sustainable Development Goals (SDGs) dictionary of labels:\\n\\n\"SDG-1\": \"End poverty in all its forms everywhere.\"\\n\"SDG-2\": \"End hunger, achieve food security and improved nutrition and promote sustainable agriculture.\"\\n\"SDG-3\": \"Ensure healthy lives and promote well-being for all at all ages.\"\\n\"SDG-4\": \"Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all.\"\\n\"SDG-5\": \"Achieve gender equality and empower all women and girls.\"\\n\"SDG-6\": \"Ensure availability and sustainable management of water and sanitation for all.\"\\n\"SDG-7\": \"Ensure access to affordable, reliable, sustainable and modern energy for all.\"\\n\"SDG-8\": \"Promote sustained, inclusive and sustainable economic growth, full and productive employment and decent work for all.\"\\n\"SDG-9\": \"Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation.\"\\n\"SDG-10\": \"Reduce inequality within and among countries.\"\\n\"SDG-11\": \"Make cities and human settlements inclusive, safe, resilient and sustainable.\"\\n\"SDG-12\": \"Ensure sustainable consumption and production patterns.\"\\n\"SDG-13\": \"Take urgent action to combat climate change and its impacts.\"\\n\"SDG-14\": \"Conserve and sustainably use the oceans, seas and marine resources for sustainable development.\"\\n\"SDG-15\": \"Protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, halt and reverse land degradation, and halt biodiversity loss.\"\\n\"SDG-16\": \"Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels.\"\\n\"SDG-0\": \"Other.\"\\n\\nChoose ONLY ONE label for each input text.\\n\\nDO NOT include the input text in your answer.\\n\\nThe input text is:\\n\\'\\'\\'\\nThis Vitamin Reduces Mental Health Problems By 50%  PsyBlog.\\n\\'\\'\\''},\n",
       "  {'role': 'assistant', 'content': '\"SDG-0\"'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e096e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system', 'content': 'You are a text classifier.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Classify the following input text within triple quotes according to the following Sustainable Development Goals (SDGs) dictionary of labels:\\n\\n\"SDG-1\": \"End poverty in all its forms everywhere.\"\\n\"SDG-2\": \"End hunger, achieve food security and improved nutrition and promote sustainable agriculture.\"\\n\"SDG-3\": \"Ensure healthy lives and promote well-being for all at all ages.\"\\n\"SDG-4\": \"Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all.\"\\n\"SDG-5\": \"Achieve gender equality and empower all women and girls.\"\\n\"SDG-6\": \"Ensure availability and sustainable management of water and sanitation for all.\"\\n\"SDG-7\": \"Ensure access to affordable, reliable, sustainable and modern energy for all.\"\\n\"SDG-8\": \"Promote sustained, inclusive and sustainable economic growth, full and productive employment and decent work for all.\"\\n\"SDG-9\": \"Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation.\"\\n\"SDG-10\": \"Reduce inequality within and among countries.\"\\n\"SDG-11\": \"Make cities and human settlements inclusive, safe, resilient and sustainable.\"\\n\"SDG-12\": \"Ensure sustainable consumption and production patterns.\"\\n\"SDG-13\": \"Take urgent action to combat climate change and its impacts.\"\\n\"SDG-14\": \"Conserve and sustainably use the oceans, seas and marine resources for sustainable development.\"\\n\"SDG-15\": \"Protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, halt and reverse land degradation, and halt biodiversity loss.\"\\n\"SDG-16\": \"Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels.\"\\n\"SDG-0\": \"Other.\"\\n\\nChoose ONLY ONE label for each input text.\\n\\nDO NOT include the input text in your answer.\\n\\nThe input text is:\\n\\'\\'\\'\\nMurray revealed on Sky Sports, “I hope not, but you never know  It\\'s why athletes need to make the most of it while they\\'re still able to because if I was to have another big injury or if something happened to the metal hip, that would be me finished  I wouldn\\'t try to come back from another operation or major surgery again so I want to keep playing a bit longer \". \"I know it\\'s not going to be going on forever, but I have an idea of when I would like to finish and it\\'s not this year\\'s Wimbledon  I don\\'t know exactly which tournament it would be or where it will be  I just have an idea of how much longer I would like to play for and I don\\'t want to put myself in a position like before I had the operation.\\n\\'\\'\\''},\n",
       "  {'role': 'assistant', 'content': '\"SDG-0\"'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ab380dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e6b2177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "dataset = train_dataset\n",
    "\n",
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6af09506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 145, 509\n",
      "mean / median: 250.8968487394958, 244.0\n",
      "p5 / p95: 205.0, 308.0\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 4, 4\n",
      "mean / median: 4.0, 4.0\n",
      "p5 / p95: 4.0, 4.0\n",
      "\n",
      "0 examples may be over the 16385 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "\n",
    "#n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "n_too_long = sum(l > 16385 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 16385 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ea813a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convo_lens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n_train_examples \u001b[38;5;241m*\u001b[39m TARGET_EPOCHS \u001b[38;5;241m>\u001b[39m MAX_TARGET_EXAMPLES:\n\u001b[1;32m     17\u001b[0m     n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_train_examples)\n\u001b[0;32m---> 19\u001b[0m n_billing_tokens_in_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mmin\u001b[39m(MAX_TOKENS_PER_EXAMPLE, length) \u001b[38;5;28;01mfor\u001b[39;00m length \u001b[38;5;129;01min\u001b[39;00m \u001b[43mconvo_lens\u001b[49m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset has ~\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_billing_tokens_in_dataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokens that will be charged for during training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBy default, you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mll train for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs on this dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'convo_lens' is not defined"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "#MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "MAX_TOKENS_PER_EXAMPLE = 16385\n",
    "\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13aed8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "dataset = val_dataset\n",
    "\n",
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13fbe5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 442, 806\n",
      "mean / median: 547.9151260504202, 541.0\n",
      "p5 / p95: 502.0, 605.1000000000004\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 6, 6\n",
      "mean / median: 6.0, 6.0\n",
      "p5 / p95: 6.0, 6.0\n",
      "\n",
      "0 examples may be over the 16385 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "\n",
    "#n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "n_too_long = sum(l > 16385 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 16385 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f76a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Apri il file .jsonl in modalità scrittura\n",
    "with open('Llama-3_Fine_Tuning_SDG_TRAIN_data.jsonl', \"w\") as file_jsonl:\n",
    "    # Scrivi ogni dizionario come una riga nel file .jsonl\n",
    "    for dizionario in train_dataset:\n",
    "        json.dump(dizionario, file_jsonl)  # Scrivi il dizionario come JSON\n",
    "        file_jsonl.write('\\n')  # Aggiungi un nuovo carattere di nuova riga alla fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6e153d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Apri il file .jsonl in modalità scrittura\n",
    "with open('Llama-3_Fine_Tuning_SDG_VAL_data.jsonl', \"w\") as file_jsonl:\n",
    "    # Scrivi ogni dizionario come una riga nel file .jsonl\n",
    "    for dizionario in val_dataset:\n",
    "        json.dump(dizionario, file_jsonl)  # Scrivi il dizionario come JSON\n",
    "        file_jsonl.write('\\n')  # Aggiungi un nuovo carattere di nuova riga alla fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2b027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
