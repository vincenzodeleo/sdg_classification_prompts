{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "464d6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tiktoken --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee826988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tiktoken # for token counting\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d41cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESEMPIO DI FORMATTAZIONE DEI TESTI PER IL FINE-TUNING DI GPT\n",
    "# {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "# {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
    "# {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da74827",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a text classifier.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f5fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(\"../data/input/sdg_17_labels_classification_dataset_4760_texts_TRAIN_2023.12.11.xlsx\")[['text', 'sdg']].rename(columns={'sdg': 'label'})\n",
    "val_df = pd.read_excel(\"../data/input/sdg_17_labels_classification_dataset_1020_texts_DEV_2023.12.11.xlsx\")[['text', 'sdg']].rename(columns={'sdg': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432cb193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This Vitamin Reduces Mental Health Problems By...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'League Of Legends' unveils new Arena game mod...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Community remembers Maddi Kingsbury at public ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  This Vitamin Reduces Mental Health Problems By...      0\n",
       "1  'League Of Legends' unveils new Arena game mod...      0\n",
       "2  Community remembers Maddi Kingsbury at public ...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fceda998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Murray revealed on Sky Sports, “I hope not, bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With age and inactive lifestyle, your joints a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Reuters) -Home health and hospice caregiver A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Murray revealed on Sky Sports, “I hope not, bu...      0\n",
       "1  With age and inactive lifestyle, your joints a...      0\n",
       "2  (Reuters) -Home health and hospice caregiver A...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffb19dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_content_part1 = \"\"\"In the following lines, a text enclosed in triple quotes will be given to you.\n",
    "\n",
    "The task is to classify the text according to the Sustainable Development Goals (SDGs) adopted by all United Nations Member States in 2015.\n",
    "\n",
    "The constraint to adhere to is that for the classification, you must select only one out of all the possible SDGs.\n",
    "\n",
    "If you believe that the text to be processed cannot be classified under any of the possible SDGs, then classify it as \"---SDG 0---\".\n",
    "\n",
    "Answer with the label only using the format: \"---LABEL---\"\n",
    "\n",
    "The input text is:\n",
    "'''\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c4e8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "for ind, row in train_df.iterrows():\n",
    "    train_dataset.append(\n",
    "        {\"messages\": [{\"role\": \"system\", \"content\": system_content}, \n",
    "                      {\"role\": \"user\", \"content\": user_content_part1 + row['text'] + \"\\n'''\"}, \n",
    "                      {\"role\": \"assistant\", \"content\": '\"---SDG '+str(row['label'])+'---\"'}\n",
    "                     ]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca4c9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = []\n",
    "for ind, row in val_df.iterrows():\n",
    "    val_dataset.append(\n",
    "        {\"messages\": [{\"role\": \"system\", \"content\": system_content}, \n",
    "                      {\"role\": \"user\", \"content\": user_content_part1 + row['text'] + \"\\n'''\"}, \n",
    "                      {\"role\": \"assistant\", \"content\": '\"SDG '+str(row['label'])+'\"'}\n",
    "                     ]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a4ed36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system', 'content': 'You are a text classifier.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'In the following lines, a text enclosed in triple quotes will be given to you.\\n\\nThe task is to classify the text according to the Sustainable Development Goals (SDGs) adopted by all United Nations Member States in 2015.\\n\\nThe constraint to adhere to is that for the classification, you must select only one out of all the possible SDGs.\\n\\nIf you believe that the text to be processed cannot be classified under any of the possible SDGs, then classify it as \"---SDG 0---\".\\n\\nAnswer with the label only using the format: \"---LABEL---\"\\n\\nThe input text is:\\n\\'\\'\\'\\nThis Vitamin Reduces Mental Health Problems By 50%  PsyBlog.\\n\\'\\'\\''},\n",
       "  {'role': 'assistant', 'content': '\"---SDG 0---\"'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e096e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system', 'content': 'You are a text classifier.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'In the following lines, a text enclosed in triple quotes will be given to you.\\n\\nThe task is to classify the text according to the Sustainable Development Goals (SDGs) adopted by all United Nations Member States in 2015.\\n\\nThe constraint to adhere to is that for the classification, you must select only one out of all the possible SDGs.\\n\\nIf you believe that the text to be processed cannot be classified under any of the possible SDGs, then classify it as \"---SDG 0---\".\\n\\nAnswer with the label only using the format: \"---LABEL---\"\\n\\nThe input text is:\\n\\'\\'\\'\\nMurray revealed on Sky Sports, “I hope not, but you never know  It\\'s why athletes need to make the most of it while they\\'re still able to because if I was to have another big injury or if something happened to the metal hip, that would be me finished  I wouldn\\'t try to come back from another operation or major surgery again so I want to keep playing a bit longer \". \"I know it\\'s not going to be going on forever, but I have an idea of when I would like to finish and it\\'s not this year\\'s Wimbledon  I don\\'t know exactly which tournament it would be or where it will be  I just have an idea of how much longer I would like to play for and I don\\'t want to put myself in a position like before I had the operation.\\n\\'\\'\\''},\n",
       "  {'role': 'assistant', 'content': '\"SDG 0\"'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ab380dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e6b2177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "dataset = train_dataset\n",
    "\n",
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6af09506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 160, 524\n",
      "mean / median: 265.91512605042016, 259.0\n",
      "p5 / p95: 220.0, 323.10000000000036\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 8, 8\n",
      "mean / median: 8.0, 8.0\n",
      "p5 / p95: 8.0, 8.0\n",
      "\n",
      "0 examples may be over the 16385 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "\n",
    "#n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "n_too_long = sum(l > 16385 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 16385 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ea813a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~1265756 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~3797268 tokens\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "#MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "MAX_TOKENS_PER_EXAMPLE = 16385\n",
    "\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13aed8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "dataset = val_dataset\n",
    "\n",
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13fbe5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 162, 419\n",
      "mean / median: 264.3921568627451, 257.0\n",
      "p5 / p95: 219.9, 321.0\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 6, 6\n",
      "mean / median: 6.0, 6.0\n",
      "p5 / p95: 6.0, 6.0\n",
      "\n",
      "0 examples may be over the 16385 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "\n",
    "#n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "n_too_long = sum(l > 16385 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 16385 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f76a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Apri il file .jsonl in modalità scrittura\n",
    "with open('Mixtral-7Bx8_Fine_Tuning_SDG_TRAIN_data.jsonl', \"w\") as file_jsonl:\n",
    "    # Scrivi ogni dizionario come una riga nel file .jsonl\n",
    "    for dizionario in train_dataset:\n",
    "        json.dump(dizionario, file_jsonl)  # Scrivi il dizionario come JSON\n",
    "        file_jsonl.write('\\n')  # Aggiungi un nuovo carattere di nuova riga alla fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6e153d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Apri il file .jsonl in modalità scrittura\n",
    "with open('Mixtral-7Bx8_Fine_Tuning_SDG_VAL_data.jsonl', \"w\") as file_jsonl:\n",
    "    # Scrivi ogni dizionario come una riga nel file .jsonl\n",
    "    for dizionario in val_dataset:\n",
    "        json.dump(dizionario, file_jsonl)  # Scrivi il dizionario come JSON\n",
    "        file_jsonl.write('\\n')  # Aggiungi un nuovo carattere di nuova riga alla fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2b027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
